# -*- coding: utf-8 -*-
"""Car Price Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qp67MOqziS9hIbnXNTCy1LouUiCEC1xp

# Task
write a python code and Start Simple: Begin with Linear Regression or Decision Tree to get a baseline.

Try Ensemble Models:

Random Forest is great for tabular data like car features.

XGBoost or LightGBM often give the best performance.

Evaluate with Metrics:

Use RÂ² Score, MAE (Mean Absolute Error), RMSE (Root Mean Squared Error) to compare models.

Tune Hyperparameters:

Use GridSearchCV or RandomizedSearchCV for boosting models.

Here is all the data you need:
"used_cars.csv"

## Data loading

### Subtask:
Load the "used_cars.csv" dataset.

**Reasoning**:
Load the "used_cars.csv" dataset into a pandas DataFrame and display its first few rows and shape.
"""

import pandas as pd

try:
    df = pd.read_csv('used_cars.csv')
    display(df.head())
    print(df.shape)
except FileNotFoundError:
    print("Error: 'used_cars.csv' not found. Please ensure the file exists in the current directory.")
    df = None
except pd.errors.EmptyDataError:
    print("Error: 'used_cars.csv' is empty.")
    df = None
except pd.errors.ParserError:
    print("Error: Unable to parse 'used_cars.csv'. Please check the file format.")
    df = None
except Exception as e:
    print(f"An unexpected error occurred: {e}")
    df = None

"""## Data exploration

### Subtask:
Explore the loaded dataset to understand its structure, identify missing values, and examine the distribution of features.

**Reasoning**:
Explore the dataset by examining its shape, data types, descriptive statistics, missing values, and distributions of features.  This will provide insights into the data structure and potential issues.

**Reasoning**:
The previous code block failed due to an inability to convert string columns to float for correlation analysis.  The error message indicates the issue is with the 'brand' column.  I will modify the code to exclude non-numeric columns from the correlation analysis and handle the 'price' column's data type.
"""

# Data Shape and Info
print(df.info())

# Descriptive Statistics
print(df.describe(include='all'))

# Missing Value Analysis
missing_values = df.isnull().sum()
missing_percentage = (missing_values / len(df)) * 100
print(f"\nMissing Values:\n{missing_values}\n\nMissing Value Percentages:\n{missing_percentage}")

# Feature Distribution Analysis (Numerical Features)
import matplotlib.pyplot as plt
numerical_features = df.select_dtypes(include=['number'])
for col in numerical_features.columns:
    plt.figure(figsize=(8, 6))  # Adjust figure size
    plt.hist(df[col].dropna(), bins=20, color='skyblue', edgecolor='black')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.title(f'Distribution of {col}')
    plt.show()

# Feature Distribution Analysis (Categorical Features)
categorical_features = df.select_dtypes(exclude=['number'])
for col in categorical_features.columns:
    plt.figure(figsize=(10, 6)) # Adjust figure size
    df[col].value_counts().plot(kind='bar', color='coral')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.title(f'Distribution of {col}')
    plt.xticks(rotation=45, ha='right') # Rotate x-axis labels
    plt.tight_layout() # Adjust layout
    plt.show()
    print(f"Unique values for {col}:\n{df[col].unique()}")

# Correlation Analysis (excluding non-numeric columns)
import seaborn as sns
# Convert 'price' to numeric, handling errors
df['price'] = df['price'].astype(str).str.replace(r'[$,]', '', regex=True)
df['price'] = pd.to_numeric(df['price'], errors='coerce')
numeric_df = df.select_dtypes(include=['number'])
correlation_matrix = numeric_df.corr()

plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Numerical Features')
plt.show()

# Data Type Verification
print("\nData Types:\n", df.dtypes)

"""## Data cleaning

### Subtask:
Clean the data by handling missing values and converting categorical features to numerical representations.

**Reasoning**:
Handle missing values, convert categorical features to numerical representations, and handle outliers according to the instructions.
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.impute import SimpleImputer

# 1. Handle Missing Values
threshold = 0.5
missing_percentage = df.isnull().sum() / len(df)
columns_to_drop = missing_percentage[missing_percentage > threshold].index
df = df.drop(columns=columns_to_drop)

numerical_features = df.select_dtypes(include=['number'])
categorical_features = df.select_dtypes(exclude=['number'])

numerical_imputer = SimpleImputer(strategy='mean')
df[numerical_features.columns] = numerical_imputer.fit_transform(df[numerical_features.columns])

categorical_imputer = SimpleImputer(strategy='most_frequent')
df[categorical_features.columns] = categorical_imputer.fit_transform(df[categorical_features.columns])

# 2. Convert Categorical Features
threshold_unique_values = 10
for col in categorical_features.columns:
    if df[col].nunique() < threshold_unique_values:
        # One-hot encoding
        ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
        encoded_features = ohe.fit_transform(df[[col]])
        feature_names = [f"{col}_{category}" for category in ohe.categories_[0]]
        encoded_df = pd.DataFrame(encoded_features, columns=feature_names)
        df = pd.concat([df, encoded_df], axis=1)
        df = df.drop(col, axis=1)
    else:
        # Label encoding
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])

# 3. Outlier Handling (Winsorizing)
for col in numerical_features.columns:
    if col != 'price':  # Don't Winsorize the target variable
        df[col] = np.clip(df[col], df[col].quantile(0.05), df[col].quantile(0.95))

# 4. Data Type Adjustments
df = df.astype({col: 'float64' for col in numerical_features.columns})

print(df.shape)
display(df.head())

"""## Feature engineering

### Subtask:
Engineer new features from existing ones to potentially improve model performance.

**Reasoning**:
Create interaction and polynomial features, then scale numerical features.
"""

import numpy as np
from sklearn.preprocessing import MinMaxScaler

# 1. Create interaction features
df['mileage_age_interaction'] = df['milage'] * (2025 - df['model_year'])
df['fuel_engine_interaction'] = df['engine'] * df['fuel_type_Gasoline']

# 2. Create polynomial features
df['mileage_squared'] = df['milage'] ** 2


# 3. Scaling/Normalization
numerical_features_to_scale = ['milage', 'model_year', 'engine', 'transmission', 'mileage_age_interaction', 'fuel_engine_interaction', 'mileage_squared']
scaler = MinMaxScaler()

df[numerical_features_to_scale] = scaler.fit_transform(df[numerical_features_to_scale])

display(df.head())

"""## Data splitting

### Subtask:
Split the data into training and testing sets.

**Reasoning**:
Split the data into training and testing sets using train_test_split.
"""

from sklearn.model_selection import train_test_split

# Separate features (X) and target variable (y)
X = df.drop('price', axis=1)
y = df['price']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""## Model training

### Subtask:
Train a Linear Regression model.

**Reasoning**:
Train a Linear Regression model using the training data.
"""

from sklearn.linear_model import LinearRegression

# Initialize the Linear Regression model
linear_model = LinearRegression()

# Train the model
linear_model.fit(X_train, y_train)

"""## Model evaluation

### Subtask:
Evaluate the trained Linear Regression model.

**Reasoning**:
Use the trained linear model to predict on the test set and evaluate the model's performance using R-squared, MAE, and RMSE.
"""

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

# Predict using the linear model
y_pred_linear = linear_model.predict(X_test)

# Evaluate the model
r2 = r2_score(y_test, y_pred_linear)
mae = mean_absolute_error(y_test, y_pred_linear)
rmse = np.sqrt(mean_squared_error(y_test, y_pred_linear))

# Store the metrics
linear_metrics = {'R-squared': r2, 'MAE': mae, 'RMSE': rmse}

# Display the evaluation metrics
print("Linear Regression Model Evaluation Metrics:")
print(f"R-squared: {r2}")
print(f"MAE: {mae}")
print(f"RMSE: {rmse}")

"""## Model training

### Subtask:
Train a Random Forest Regressor model.

**Reasoning**:
Train a RandomForestRegressor model using the training data.
"""

from sklearn.ensemble import RandomForestRegressor

# Initialize the Random Forest Regressor model
rf_model = RandomForestRegressor(random_state=42)

# Train the model
rf_model.fit(X_train, y_train)

"""## Model evaluation

### Subtask:
Evaluate the trained Random Forest Regressor model.

**Reasoning**:
Predict the target variable using the trained Random Forest Regressor model and evaluate its performance using R-squared, MAE, and RMSE.
"""

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

# Predict using the random forest model
y_pred_rf = rf_model.predict(X_test)

# Evaluate the model
r2 = r2_score(y_test, y_pred_rf)
mae = mean_absolute_error(y_test, y_pred_rf)
rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))

# Store the metrics
rf_metrics = {'R-squared': r2, 'MAE': mae, 'RMSE': rmse}

# Display the evaluation metrics
print("Random Forest Model Evaluation Metrics:")
print(f"R-squared: {r2}")
print(f"MAE: {mae}")
print(f"RMSE: {rmse}")

"""## Model training

### Subtask:
Train an XGBoost model.

**Reasoning**:
Train an XGBoost model using the training data.
"""

from xgboost import XGBRegressor

# Initialize the XGBoost Regressor model
xgb_model = XGBRegressor(random_state=42)

# Train the model
xgb_model.fit(X_train, y_train)

"""## Model optimization

### Subtask:
Tune the hyperparameters of the XGBoost model using RandomizedSearchCV.

**Reasoning**:
Define the hyperparameter grid, initialize RandomizedSearchCV, fit it to the training data, and extract the best model.
"""

from sklearn.model_selection import RandomizedSearchCV
from xgboost import XGBRegressor
import numpy as np

# Define the hyperparameter grid
param_grid = {
    'n_estimators': np.arange(50, 500, 50),  # Number of trees
    'learning_rate': np.linspace(0.01, 0.3, 10),  # Step size shrinkage used in update to prevent overfitting
    'max_depth': np.arange(3, 10),  # Maximum depth of a tree
    'subsample': np.linspace(0.5, 1, 6),  # Subsample ratio of the training instances
    'colsample_bytree': np.linspace(0.5, 1, 6),  # Subsample ratio of columns when constructing each tree
}

# Initialize XGBoost model
xgb_model = XGBRegressor(random_state=42)

# Initialize RandomizedSearchCV
random_search = RandomizedSearchCV(
    estimator=xgb_model,
    param_distributions=param_grid,
    scoring='neg_mean_squared_error',
    n_iter=20,  # Number of random combinations to try
    cv=5,  # Cross-validation folds
    random_state=42,
    verbose=1,
    n_jobs=-1 #Use all processors
)

# Fit RandomizedSearchCV to the training data
random_search.fit(X_train, y_train)

# Get the best hyperparameters and best estimator
best_params = random_search.best_params_
best_xgb_model = random_search.best_estimator_

print("Best Hyperparameters:", best_params)

"""## Model evaluation

### Subtask:
Evaluate the tuned XGBoost model and compare its performance with the Linear Regression and Random Forest models.

**Reasoning**:
Evaluate the tuned XGBoost model, calculate its metrics, and compare it with the Linear Regression and Random Forest models. Create a summary table to present the results.
"""

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np
import pandas as pd

# Predict using the tuned XGBoost model
y_pred_xgb = best_xgb_model.predict(X_test)

# Evaluate the tuned XGBoost model
r2_xgb = r2_score(y_test, y_pred_xgb)
mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))

# Store the XGBoost metrics
xgb_metrics = {'R-squared': r2_xgb, 'MAE': mae_xgb, 'RMSE': rmse_xgb}

# Create a comparison table
model_comparison = pd.DataFrame({
    'Model': ['Linear Regression', 'Random Forest', 'Tuned XGBoost'],
    'R-squared': [linear_metrics['R-squared'], rf_metrics['R-squared'], r2_xgb],
    'MAE': [linear_metrics['MAE'], rf_metrics['MAE'], mae_xgb],
    'RMSE': [linear_metrics['RMSE'], rf_metrics['RMSE'], rmse_xgb]
})

# Display the comparison table
display(model_comparison)

# Discussion of results
print("\nModel Performance Discussion:")
print("Based on the evaluation metrics, the tuned XGBoost model generally shows the best performance, "
      "with the highest R-squared, lowest MAE and lowest RMSE, but there is a possibility of overfitting.")
print("The Linear Regression model shows the worst performance across all metrics. "
      "This could be because of the model's simplistic assumptions about the data.")
print("The Random Forest model falls between the two extremes. "
      "Potential limitations of all these models could be the data's quality, the model choice, and overfitting issues.")

"""## Summary:

### Q&A

* **Which model performed best?** The tuned XGBoost model showed the best performance with the highest R-squared (0.1114), lowest MAE (19320.28), and lowest RMSE (134767.11).  However, there's a concern about potential overfitting.
* **Which model performed worst?** The Linear Regression model performed the worst across all metrics.
* **What are the potential limitations of the models?** Potential limitations include data quality, model choice (simplicity of linear regression vs. complexity of XGBoost), and overfitting (especially in the XGBoost model).


### Data Analysis Key Findings

* **Missing Data:** Several columns had missing values; those with more than 50% missing were dropped.  Numerical features were imputed using the mean, and categorical features were imputed using the most frequent value.
* **Categorical Feature Encoding:** Categorical features were converted using one-hot encoding (for features with fewer than 10 unique values) and label encoding (for features with 10 or more).
* **Outlier Handling:** Outliers in numerical features (except price) were handled by Winsorizing (clipping values at 5th and 95th percentiles).
* **Feature Engineering:**  New interaction and polynomial features were created (e.g., 'mileage_age_interaction', 'fuel_engine_interaction', 'mileage_squared'). Numerical features were then scaled using `MinMaxScaler`.
* **Model Performance Comparison:**
    * **Tuned XGBoost:** R-squared: 0.1114, MAE: 19320.28, RMSE: 134767.11 (best performance, but potential overfitting).
    * **Random Forest:** R-squared: 0.084, MAE: 20334.23, RMSE: 136794.46 (intermediate performance).
    * **Linear Regression:** R-squared: 0.033, MAE: 28639.74, RMSE: 140593.49 (worst performance).
* **Hyperparameter Tuning:** XGBoost hyperparameters were tuned using `RandomizedSearchCV`, resulting in the best hyperparameter combination `{'subsample': 0.7, 'n_estimators': 450, 'max_depth': 4, 'learning_rate': 0.07444444444444444, 'colsample_bytree': 0.5}`.


### Insights or Next Steps

* **Investigate Overfitting:** Given the potential overfitting in the XGBoost model, explore regularization techniques (e.g., L1/L2 regularization) or try reducing model complexity. Further evaluation using cross-validation would help assess the model's generalization ability better.
* **Feature Selection/Importance:** Analyze feature importance scores from the models to identify the most influential features and potentially eliminate irrelevant ones to improve model efficiency and generalization.

"""